{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d37bbc9-d209-4e0e-833b-09ea0fd2d8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in ./myenv/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in ./myenv/lib/python3.13/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in ./myenv/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.13/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./myenv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./myenv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.13/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./myenv/lib/python3.13/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in ./myenv/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in ./myenv/lib/python3.13/site-packages (11.3.0)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.13/site-packages (3.10.6)\n",
      "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.13/site-packages (2.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./myenv/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./myenv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: ipywidgets in ./myenv/lib/python3.13/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myenv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install opencv-python pillow matplotlib scikit-learn numpy\n",
    "!pip install ipywidgets  # –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models, datasets\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aece385b-f77e-49e0-962f-c8ad21118c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: data/raw/car\n",
      "Created: data/raw/not_car\n",
      "Created: data/processed/views/train/front\n",
      "Created: data/processed/views/train/side\n",
      "Created: data/processed/views/train/rear\n",
      "Created: data/processed/views/val/front\n",
      "Created: data/processed/views/val/side\n",
      "Created: data/processed/views/val/rear\n",
      "Created: data/processed/damage/train/damaged\n",
      "Created: data/processed/damage/train/intact\n",
      "Created: data/processed/damage/val/damaged\n",
      "Created: data/processed/damage/val/intact\n",
      "Created: data/processed/dirt/train/dirty\n",
      "Created: data/processed/dirt/train/clean\n",
      "Created: data/processed/dirt/val/dirty\n",
      "Created: data/processed/dirt/val/clean\n",
      "Created: models\n",
      "Created: test_images\n",
      "Folder structure created successfully!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 2: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫\n",
    "def create_folder_structure():\n",
    "    folders = [\n",
    "        'data/raw/car',\n",
    "        'data/raw/not_car',\n",
    "        'data/processed/views/train/front',\n",
    "        'data/processed/views/train/side', \n",
    "        'data/processed/views/train/rear',\n",
    "        'data/processed/views/val/front',\n",
    "        'data/processed/views/val/side',\n",
    "        'data/processed/views/val/rear',\n",
    "        'data/processed/damage/train/damaged',\n",
    "        'data/processed/damage/train/intact',\n",
    "        'data/processed/damage/val/damaged', \n",
    "        'data/processed/damage/val/intact',\n",
    "        'data/processed/dirt/train/dirty',\n",
    "        'data/processed/dirt/train/clean',\n",
    "        'data/processed/dirt/val/dirty',\n",
    "        'data/processed/dirt/val/clean',\n",
    "        'models',\n",
    "        'test_images'\n",
    "    ]\n",
    "    \n",
    "    for folder in folders:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        print(f\"Created: {folder}\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º README —Ñ–∞–π–ª—ã\n",
    "    for view in ['front', 'side', 'rear']:\n",
    "        with open(f'data/processed/views/train/{view}/README.txt', 'w') as f:\n",
    "            f.write(f\"Place {view} view car images here\")\n",
    "        with open(f'data/processed/views/val/{view}/README.txt', 'w') as f:\n",
    "            f.write(f\"Place {view} view car images here (validation)\")\n",
    "    \n",
    "    print(\"Folder structure created successfully!\")\n",
    "\n",
    "create_folder_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886cf92b-110d-45f9-ae17-dd7d1c74d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤: /Users/ashko/Downloads\n",
      "--------------------------------------------------\n",
      "üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –ó–∞–≥—Ä—É–∑–∫–∞—Ö: 56\n",
      "üñºÔ∏è –ò–∑ –Ω–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 21\n",
      "üìã –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ó–∞–≥—Ä—É–∑–∫–∞—Ö:\n",
      "   üìÑ IMG_6538.PNG\n",
      "   üìÑ IMG_7344.JPG\n",
      "   üìÑ IMG_7024.PNG\n",
      "   üìÑ 6f3f4105-ec19-4569-b106-941b5f325b56.JPG\n",
      "   üìÑ _.png\n",
      "   üìÑ car_scratch.png\n",
      "   üìÑ ChatGPT Image Aug 9, 2025 at 12_26_31 AM.png\n",
      "   üìÑ ChatGPT Image Sep 11, 2025 at 12_03_35 AM.png\n",
      "   üìÑ IMG_7497.JPG\n",
      "   üìÑ IMG_7496.JPG\n",
      "   ... –∏ –µ—â–µ 11 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "\n",
      "üîé –ü–æ–∏—Å–∫ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤:\n",
      "   ‚úÖ Car: –Ω–∞–π–¥–µ–Ω–æ 1 —Ñ–∞–π–ª–æ–≤\n",
      "      üìÑ car_scratch.png\n",
      "   ‚ùå car_perfect_sides: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n",
      "   ‚ùå front: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n",
      "   ‚ùå rear: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n",
      "   ‚úÖ car_scratch: –Ω–∞–π–¥–µ–Ω–æ 1 —Ñ–∞–π–ª–æ–≤\n",
      "      üìÑ car_scratch.png\n",
      "   ‚ùå rust_and_scratch: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n",
      "   ‚ùå car_scratch_and_dent: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n",
      "\n",
      "üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤: 2\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 3: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è copy_from_downloads\n",
    "def copy_from_downloads(target_folder, keywords=None, file_limit=10):\n",
    "    \"\"\"\n",
    "    –ö–æ–ø–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏ –ó–∞–≥—Ä—É–∑–∫–∏ –≤ —Ü–µ–ª–µ–≤—É—é –ø–∞–ø–∫—É\n",
    "    \"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "    else:  # Linux/Mac\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    if not os.path.exists(downloads_path):\n",
    "        print(f\"‚ùå –ü–∞–ø–∫–∞ –ó–∞–≥—Ä—É–∑–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {downloads_path}\")\n",
    "        return 0\n",
    "    \n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    \n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.JPG', '*.JPEG', '*.PNG']\n",
    "    all_images = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        all_images.extend(glob.glob(os.path.join(downloads_path, ext)))\n",
    "    \n",
    "    if keywords:\n",
    "        filtered_images = []\n",
    "        for img_path in all_images:\n",
    "            filename = os.path.basename(img_path).lower()\n",
    "            # –ò—â–µ–º –õ–Æ–ë–û–ï –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞\n",
    "            if any(keyword.lower() in filename for keyword in keywords):\n",
    "                filtered_images.append(img_path)\n",
    "        all_images = filtered_images\n",
    "    \n",
    "    images_to_copy = all_images[:file_limit]\n",
    "    \n",
    "    if not images_to_copy:\n",
    "        print(\"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ –ó–∞–≥—Ä—É–∑–∫–∏\")\n",
    "        print(f\"–ò—Å–∫–∞–ª —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ: {keywords}\")\n",
    "        return 0\n",
    "    \n",
    "    copied_count = 0\n",
    "    for img_path in images_to_copy:\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            target_path = os.path.join(target_folder, filename)\n",
    "            \n",
    "            counter = 1\n",
    "            while os.path.exists(target_path):\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                target_path = os.path.join(target_folder, f\"{name}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "            \n",
    "            shutil.copy2(img_path, target_path)\n",
    "            print(f\"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {filename} -> {target_folder}\")\n",
    "            copied_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ {filename}: {e}\")\n",
    "    \n",
    "    print(f\"üìä –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {copied_count}/{len(images_to_copy)}\")\n",
    "    return copied_count\n",
    "\n",
    "# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n",
    "def debug_file_search():\n",
    "    \"\"\"–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥–∏—Ç —Å–∏—Å—Ç–µ–º–∞\"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "    else:  # Linux/Mac\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    print(f\"üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤: {downloads_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # –í—Å–µ —Ñ–∞–π–ª—ã –≤ –∑–∞–≥—Ä—É–∑–∫–∞—Ö\n",
    "    all_files = os.listdir(downloads_path)\n",
    "    image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]\n",
    "    \n",
    "    print(f\"üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –ó–∞–≥—Ä—É–∑–∫–∞—Ö: {len(all_files)}\")\n",
    "    print(f\"üñºÔ∏è –ò–∑ –Ω–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}\")\n",
    "    \n",
    "    if image_files:\n",
    "        print(\"üìã –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ó–∞–≥—Ä—É–∑–∫–∞—Ö:\")\n",
    "        for img in image_files[:10]:  # –ø–µ—Ä–≤—ã–µ 10\n",
    "            print(f\"   üìÑ {img}\")\n",
    "        if len(image_files) > 10:\n",
    "            print(f\"   ... –∏ –µ—â–µ {len(image_files) - 10} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "    \n",
    "    # –í–∞—à–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "    your_files = ['Car', 'car_perfect_sides', 'front', 'rear', 'car_scratch', 'rust_and_scratch', 'car_scratch_and_dent']\n",
    "    \n",
    "    print(\"\\nüîé –ü–æ–∏—Å–∫ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
    "    found_count = 0\n",
    "    for pattern in your_files:\n",
    "        found_files = [f for f in image_files if pattern.lower() in f.lower()]\n",
    "        if found_files:\n",
    "            print(f\"   ‚úÖ {pattern}: –Ω–∞–π–¥–µ–Ω–æ {len(found_files)} —Ñ–∞–π–ª–æ–≤\")\n",
    "            for file in found_files[:3]:  # –ø–µ—Ä–≤—ã–µ 3\n",
    "                print(f\"      üìÑ {file}\")\n",
    "            if len(found_files) > 3:\n",
    "                print(f\"      ... –∏ –µ—â–µ {len(found_files) - 3}\")\n",
    "            found_count += len(found_files)\n",
    "        else:\n",
    "            print(f\"   ‚ùå {pattern}: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\")\n",
    "    \n",
    "    print(f\"\\nüìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤: {found_count}\")\n",
    "\n",
    "# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ç–ª–∞–¥–∫—É —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç\n",
    "debug_file_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cadcf40-4f3a-4942-85ed-6dcf0f902585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ò—â—É –≤–∞—à–∏ –ø–∞–ø–∫–∏ –≤: /Users/ashko/Downloads\n",
      "------------------------------------------------------------\n",
      "‚úÖ –ù–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞: Car\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_copied\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mcopy_from_your_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\u001b[39;00m\n\u001b[32m     91\u001b[39m check_data_availability()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mcopy_from_your_folders\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m images = []\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33m*.jpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m*.jpeg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     images.extend(\u001b[43mglob\u001b[49m.glob(os.path.join(source_folder, ext)))\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üì∑ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images:\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–∞–ø–∫—É\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 3.5: –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ –≤–∞—à–∏—Ö –ø–∞–ø–æ–∫ –≤ –Ω—É–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "def copy_from_your_folders():\n",
    "    \"\"\"–ö–æ–ø–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –∏–∑ –≤–∞—à–∏—Ö –ø–∞–ø–æ–∫ –≤ –Ω—É–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "    else:  # Linux/Mac\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    print(f\"üîç –ò—â—É –≤–∞—à–∏ –ø–∞–ø–∫–∏ –≤: {downloads_path}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # –í–∞—à–∏ –ø–∞–ø–∫–∏ –∏ –∫—É–¥–∞ –∏—Ö –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å\n",
    "    folder_mapping = {\n",
    "        'Car': 'data/processed/views/train/front',\n",
    "        'car_perfect_sides': 'data/processed/views/train/side', \n",
    "        'front': 'data/processed/views/train/front',\n",
    "        'rear': 'data/processed/views/train/rear',\n",
    "        'car_scratch': 'data/processed/damage/train/damaged',\n",
    "        'rust_and_scratch': 'data/processed/damage/train/damaged',\n",
    "        'car_scratch_and_dent': 'data/processed/damage/train/damaged'\n",
    "    }\n",
    "    \n",
    "    total_copied = 0\n",
    "    found_folders = []\n",
    "    \n",
    "    # –ò—â–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É\n",
    "    for folder_name, target_folder in folder_mapping.items():\n",
    "        source_folder = os.path.join(downloads_path, folder_name)\n",
    "        \n",
    "        if os.path.exists(source_folder) and os.path.isdir(source_folder):\n",
    "            found_folders.append(folder_name)\n",
    "            print(f\"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞: {folder_name}\")\n",
    "            \n",
    "            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ\n",
    "            images = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                images.extend(glob.glob(os.path.join(source_folder, ext)))\n",
    "            \n",
    "            print(f\"   üì∑ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}\")\n",
    "            \n",
    "            if images:\n",
    "                # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–∞–ø–∫—É\n",
    "                os.makedirs(target_folder, exist_ok=True)\n",
    "                \n",
    "                # –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "                folder_copied = 0\n",
    "                for img_path in images:\n",
    "                    try:\n",
    "                        filename = os.path.basename(img_path)\n",
    "                        target_path = os.path.join(target_folder, filename)\n",
    "                        \n",
    "                        # –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏\n",
    "                        counter = 1\n",
    "                        while os.path.exists(target_path):\n",
    "                            name, ext = os.path.splitext(filename)\n",
    "                            target_path = os.path.join(target_folder, f\"{name}_{counter}{ext}\")\n",
    "                            counter += 1\n",
    "                        \n",
    "                        shutil.copy2(img_path, target_path)\n",
    "                        print(f\"      ‚úÖ {filename}\")\n",
    "                        folder_copied += 1\n",
    "                        total_copied += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"      ‚ùå –û—à–∏–±–∫–∞ —Å {filename}: {e}\")\n",
    "                \n",
    "                print(f\"   üìä –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ {folder_name}: {folder_copied} —Ñ–∞–π–ª–æ–≤\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå –í –ø–∞–ø–∫–µ {folder_name} –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "        else:\n",
    "            print(f\"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_name}\")\n",
    "    \n",
    "    print(f\"\\nüìä –ò—Ç–æ–≥:\")\n",
    "    print(f\"–ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫: {len(found_folders)}\")\n",
    "    print(f\"–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_copied}\")\n",
    "    \n",
    "    if not found_folders:\n",
    "        print(\"\\nüîé –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ –ó–∞–≥—Ä—É–∑–∫–∏:\")\n",
    "        all_items = os.listdir(downloads_path)\n",
    "        folders = [item for item in all_items if os.path.isdir(os.path.join(downloads_path, item))]\n",
    "        print(f\"–í—Å–µ–≥–æ –ø–∞–ø–æ–∫ –≤ –ó–∞–≥—Ä—É–∑–∫–∞—Ö: {len(folders)}\")\n",
    "        for folder in folders:\n",
    "            print(f\"   üìÅ {folder}\")\n",
    "    \n",
    "    return total_copied\n",
    "\n",
    "# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é\n",
    "copy_from_your_folders()\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "check_data_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f10499-1435-4ecf-8148-3fe0ac2654ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "üìÅ data/processed/views/train/front: 413 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "üìÅ data/processed/views/train/side: 1037 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "üìÅ data/processed/views/train/rear: 436 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 3.5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "def check_and_create_test_data():\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\"\"\"\n",
    "    print(\"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    \n",
    "    # –ü–∞–ø–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å\n",
    "    required_folders = [\n",
    "        'data/processed/views/train/front',\n",
    "        'data/processed/views/train/side',\n",
    "        'data/processed/views/train/rear',\n",
    "        'data/processed/views/val/front',\n",
    "        'data/processed/views/val/side',\n",
    "        'data/processed/views/val/rear'\n",
    "    ]\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É\n",
    "    for folder in required_folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {folder}\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    train_folders = [\n",
    "        'data/processed/views/train/front',\n",
    "        'data/processed/views/train/side',\n",
    "        'data/processed/views/train/rear'\n",
    "    ]\n",
    "    \n",
    "    has_data = False\n",
    "    for folder in train_folders:\n",
    "        if os.path.exists(folder):\n",
    "            images = [f for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                print(f\"üìÅ {folder}: {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "                has_data = True\n",
    "            else:\n",
    "                print(f\"‚ùå {folder}: –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "    \n",
    "    if not has_data:\n",
    "        print(\"\\nüìù –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...\")\n",
    "        create_sample_images()\n",
    "        print(\"‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω—ã!\")\n",
    "    \n",
    "    return has_data\n",
    "\n",
    "def create_sample_images():\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\"\"\"\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    \n",
    "    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∫—É—Ä—Å–æ–≤\n",
    "    colors = {\n",
    "        'front': (255, 0, 0),    # –ö—Ä–∞—Å–Ω—ã–π - –ø–µ—Ä–µ–¥\n",
    "        'side': (0, 255, 0),     # –ó–µ–ª–µ–Ω—ã–π - –±–æ–∫\n",
    "        'rear': (0, 0, 255)      # –°–∏–Ω–∏–π - –∑–∞–¥\n",
    "    }\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–æ 5 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∫—É—Ä—Å–∞\n",
    "    for view, color in colors.items():\n",
    "        folder_path = f'data/processed/views/train/{view}'\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        for i in range(5):\n",
    "            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ü–≤–µ—Ç–Ω—ã–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–º\n",
    "            img_array = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "            img_array[20:80, 20:80] = color\n",
    "            \n",
    "            img = Image.fromarray(img_array)\n",
    "            img.save(os.path.join(folder_path, f'{view}_sample_{i+1}.jpg'))\n",
    "            print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ: {view}_sample_{i+1}.jpg\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –Ω–µ–º–Ω–æ–≥–æ validation –¥–∞–Ω–Ω—ã—Ö\n",
    "    for view in ['front', 'side', 'rear']:\n",
    "        val_folder = f'data/processed/views/val/{view}'\n",
    "        os.makedirs(val_folder, exist_ok=True)\n",
    "        \n",
    "        # –ö–æ–ø–∏—Ä—É–µ–º –ø–æ 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–∑ train –≤ val\n",
    "        train_folder = f'data/processed/views/train/{view}'\n",
    "        if os.path.exists(train_folder):\n",
    "            images = [f for f in os.listdir(train_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                src_path = os.path.join(train_folder, images[0])\n",
    "                dst_path = os.path.join(val_folder, f'val_{images[0]}')\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ validation: {dst_path}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "has_data = check_and_create_test_data()\n",
    "\n",
    "# –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã\n",
    "if not has_data:\n",
    "    print(\"\\nüéØ –î–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\")\n",
    "    print(\"1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\")\n",
    "    print(\"2. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à–∏ —Ñ–∞–π–ª—ã –∏–∑ –ó–∞–≥—Ä—É–∑–æ–∫\")\n",
    "    print(\"3. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –¥–µ–π—Å—Ç–≤–∏–π\n",
    "    use_test_btn = widgets.Button(description=\"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\", button_style='success')\n",
    "    copy_files_btn = widgets.Button(description=\"üì• –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–æ–∏ —Ñ–∞–π–ª—ã\", button_style='info')\n",
    "    check_again_btn = widgets.Button(description=\"üîÑ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–Ω–æ–≤–∞\", button_style='warning')\n",
    "    \n",
    "    test_data_output = widgets.Output()\n",
    "    \n",
    "    def on_use_test_click(b):\n",
    "        with test_data_output:\n",
    "            clear_output()\n",
    "            print(\"üîÑ –ó–∞–ø—É—Å–∫–∞—é –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "            # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "    \n",
    "    def on_copy_files_click(b):\n",
    "        with test_data_output:\n",
    "            clear_output()\n",
    "            print(\"üì• –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∫–ª–∞–¥–∫—É 'üéØ –í–∞—à–∏ —Ñ–∞–π–ª—ã' –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
    "            auto_sort_your_files()\n",
    "    \n",
    "    def on_check_again_click(b):\n",
    "        with test_data_output:\n",
    "            clear_output()\n",
    "            check_and_create_test_data()\n",
    "    \n",
    "    use_test_btn.on_click(on_use_test_click)\n",
    "    copy_files_btn.on_click(on_copy_files_click)\n",
    "    check_again_btn.on_click(on_check_again_click)\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h4>üö® –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!</h4>\"),\n",
    "        use_test_btn,\n",
    "        copy_files_btn, \n",
    "        check_again_btn,\n",
    "        test_data_output\n",
    "    ]))\n",
    "else:\n",
    "    print(\"‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339c9454-de38-4e51-95dd-25ed47cec3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c251af2df08041b48434d9a7faf15a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='üöÄ –ê–≤—Ç–æ-—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –º–æ–∏—Ö —Ñ–∞–π–ª–æ–≤', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba9b198fa5a4e31832aa90af8af7015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤\n",
    "def auto_sort_your_files():\n",
    "    \"\"\"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤–∞—à–∏ —Ñ–∞–π–ª—ã –ø–æ –Ω—É–∂–Ω—ã–º –ø–∞–ø–∫–∞–º\"\"\"\n",
    "    found_files = analyze_your_files()\n",
    "    \n",
    "    if not found_files:\n",
    "        print(\"‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –æ–Ω–∏ –≤ –ø–∞–ø–∫–µ –ó–∞–≥—Ä—É–∑–∫–∏\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # –ü—Ä–∞–≤–∏–ª–∞ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –¥–ª—è –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤\n",
    "    sorting_rules = {\n",
    "        'front': 'data/processed/views/train/front',\n",
    "        'rear': 'data/processed/views/train/rear',\n",
    "        'car_perfect_sides': 'data/processed/views/train/side',\n",
    "        'car_scratch': 'data/processed/damage/train/damaged',\n",
    "        'rust_and_scratch': 'data/processed/damage/train/damaged', \n",
    "        'car_scratch_and_dent': 'data/processed/damage/train/damaged'\n",
    "    }\n",
    "    \n",
    "    total_copied = 0\n",
    "    \n",
    "    for filename, files in found_files.items():\n",
    "        if filename in sorting_rules:\n",
    "            target_folder = sorting_rules[filename]\n",
    "            print(f\"\\nüìÅ –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ '{filename}' -> {target_folder}:\")\n",
    "            \n",
    "            for file_path in files:\n",
    "                try:\n",
    "                    file_name = os.path.basename(file_path)\n",
    "                    target_path = os.path.join(target_folder, file_name)\n",
    "                    \n",
    "                    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ—Ç\n",
    "                    os.makedirs(target_folder, exist_ok=True)\n",
    "                    \n",
    "                    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª\n",
    "                    shutil.copy2(file_path, target_path)\n",
    "                    print(f\"   ‚úÖ {file_name}\")\n",
    "                    total_copied += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå –û—à–∏–±–∫–∞ —Å {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä –ò—Ç–æ–≥–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {total_copied} —Ñ–∞–π–ª–æ–≤\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    check_data_availability()\n",
    "    \n",
    "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å\n",
    "    print(\"\\nüéØ –í–∞—à–∏ —Ñ–∞–π–ª—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã:\")\n",
    "    for filename, target in sorting_rules.items():\n",
    "        if filename in found_files:\n",
    "            files_count = len(found_files[filename])\n",
    "            print(f\"   {filename} -> {target}: {files_count} —Ñ–∞–π–ª–æ–≤\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏\n",
    "auto_sort_btn = widgets.Button(description=\"üöÄ –ê–≤—Ç–æ-—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –º–æ–∏—Ö —Ñ–∞–π–ª–æ–≤\", button_style='success')\n",
    "auto_sort_output = widgets.Output()\n",
    "\n",
    "def on_auto_sort_click(b):\n",
    "    with auto_sort_output:\n",
    "        clear_output()\n",
    "        auto_sort_your_files()\n",
    "\n",
    "auto_sort_btn.on_click(on_auto_sort_click)\n",
    "\n",
    "print(\"üéØ –î–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
    "display(auto_sort_btn)\n",
    "display(auto_sort_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e35a35-09ce-40e8-a0dd-c5ca332dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 4: –ö–ª–∞—Å—Å—ã –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "class ViewDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['front', 'side', 'rear']\n",
    "        self.images = []\n",
    "        \n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append({\n",
    "                            'path': os.path.join(class_dir, img_name),\n",
    "                            'label': class_idx\n",
    "                        })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        image = Image.open(img_info['path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_info['label']\n",
    "\n",
    "class DamageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['damaged', 'intact']\n",
    "        self.images = []\n",
    "        \n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append({\n",
    "                            'path': os.path.join(class_dir, img_name),\n",
    "                            'label': class_idx\n",
    "                        })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        image = Image.open(img_info['path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_info['label']\n",
    "\n",
    "# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e99f1d2-4ef9-4106-a875-67ae950cbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 5: –§—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, model_name):\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è live-–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    plt.ion()  # –í–∫–ª—é—á–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # –û–±—É—á–µ–Ω–∏–µ\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "        # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "        val_accuracy = 100 * val_correct / val_total if val_total > 0 else 0\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), f'models/{model_name}.pth')\n",
    "        \n",
    "        # –û–±–Ω–æ–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫\n",
    "        clear_output(wait=True)\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        \n",
    "        ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "        ax1.plot(val_losses, label='Val Loss', color='red')\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(train_accuracies, label='Train Accuracy', color='green')\n",
    "        ax2.plot(val_accuracies, label='Val Accuracy', color='orange')\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "        print(f'Best Val Accuracy: {best_accuracy:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    plt.ioff()\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0fd279d-dbde-4c96-9ab7-5371ba016169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "‚úÖ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_view_classifier():\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä–∞–∫—É—Ä—Å–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"üöó Training View Classifier...\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"‚ùå No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"‚ùå No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Training images: {len(train_dataset)}\")\n",
    "    print(f\"üìä Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 –∫–ª–∞—Å—Å–∞: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 5 —ç–ø–æ—Ö –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a184fdc9-d8e5-4351-96c8-82d015df3132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "‚úÖ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_view_classifier():\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä–∞–∫—É—Ä—Å–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"üöó Training View Classifier...\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"‚ùå No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"‚ùå No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Training images: {len(train_dataset)}\")\n",
    "    print(f\"üìä Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 –∫–ª–∞—Å—Å–∞: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 5 —ç–ø–æ—Ö –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12a19f0-4d66-45e9-8ecc-5f6bcd8a7c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "‚úÖ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_view_classifier():\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä–∞–∫—É—Ä—Å–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"üöó Training View Classifier...\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"‚ùå No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"‚ùå No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Training images: {len(train_dataset)}\")\n",
    "    print(f\"üìä Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 –∫–ª–∞—Å—Å–∞: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 5 —ç–ø–æ—Ö –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a4fa27-8030-4045-92c1-66ec66167295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "‚úÖ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_view_classifier():\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä–∞–∫—É—Ä—Å–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"üöó Training View Classifier...\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"‚ùå No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"‚ùå No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Training images: {len(train_dataset)}\")\n",
    "    print(f\"üìä Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 –∫–ª–∞—Å—Å–∞: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 5 —ç–ø–æ—Ö –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a223c0d6-e2ac-4c90-8de6-cacca35bbc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "‚úÖ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "def train_view_classifier():\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ä–∞–∫—É—Ä—Å–æ–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"üöó Training View Classifier...\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"‚ùå No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"‚ùå No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìä Training images: {len(train_dataset)}\")\n",
    "    print(f\"üìä Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 –∫–ª–∞—Å—Å–∞: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 5 —ç–ø–æ—Ö –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e95329-8f6d-467e-aafa-b6bc5312fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eae30d27a249358c36ce55d230401d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b4f57fdb4482ba1cc06c2bff61d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6.1: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞\n",
    "def quick_test_training():\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è...\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç\n",
    "    check_and_create_test_data()\n",
    "    \n",
    "    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "    model = train_view_classifier()\n",
    "    \n",
    "    if model is not None:\n",
    "        print(\"üéâ –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n",
    "        print(\"–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ:\")\n",
    "        print(\"1. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Å–≤–æ–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "        print(\"2. –û–±—É—á–∏—Ç—å –Ω–∞ –ø–æ–ª–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö\")\n",
    "        print(\"3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É\")\n",
    "    else:\n",
    "        print(\"‚ùå –¢–µ—Å—Ç –Ω–µ —É–¥–∞–ª—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.\")\n",
    "\n",
    "# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞\n",
    "quick_test_btn = widgets.Button(description=\"‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è\", button_style='info')\n",
    "quick_test_output = widgets.Output()\n",
    "\n",
    "def on_quick_test_click(b):\n",
    "    with quick_test_output:\n",
    "        clear_output()\n",
    "        quick_test_training()\n",
    "\n",
    "quick_test_btn.on_click(on_quick_test_click)\n",
    "\n",
    "print(\"\\n‚ö° –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞:\")\n",
    "display(quick_test_btn)\n",
    "display(quick_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e543c0-82e5-47e5-9ac2-908adf233671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashko/myenv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/ashko/myenv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ View classifier weights loaded\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 7: Car Detection System\n",
    "class CarDetectionSystem:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "        self.car_detector = self._load_car_detector()\n",
    "        self.view_classifier = self._load_view_classifier()\n",
    "        self.damage_classifier = self._load_damage_classifier()\n",
    "        self.dirt_classifier = self._load_dirt_classifier()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _load_car_detector(self):\n",
    "        model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        model.eval()\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _load_view_classifier(self):\n",
    "        model = models.resnet18(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "        # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('models/view_classifier.pth', map_location=self.device))\n",
    "            print(\"‚úÖ View classifier weights loaded\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Using untrained view classifier\")\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _load_damage_classifier(self):\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _load_dirt_classifier(self):\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def detect_car(self, image):\n",
    "        image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.car_detector(image_tensor)\n",
    "        \n",
    "        car_boxes = []\n",
    "        if 'boxes' in predictions[0]:\n",
    "            for box, label, score in zip(predictions[0]['boxes'], \n",
    "                                       predictions[0]['labels'], \n",
    "                                       predictions[0]['scores']):\n",
    "                if label == 3 and score > 0.5:  # –∞–≤—Ç–æ–º–æ–±–∏–ª—å –≤ COCO\n",
    "                    car_boxes.append(box.cpu().numpy())\n",
    "        \n",
    "        return car_boxes\n",
    "    \n",
    "    def classify_view(self, car_image):\n",
    "        image_tensor = self.transform(car_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.view_classifier(image_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        view_classes = ['front', 'side', 'rear']\n",
    "        return view_classes[predicted.item()]\n",
    "    \n",
    "    def analyze_car_state(self, car_image):\n",
    "        image_tensor = self.transform(car_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # –ê–Ω–∞–ª–∏–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π\n",
    "        with torch.no_grad():\n",
    "            damage_output = self.damage_classifier(image_tensor)\n",
    "            damage_probs = torch.softmax(damage_output, dim=1)\n",
    "            damage_status = 'damaged' if torch.argmax(damage_probs) == 0 else 'intact'\n",
    "            damage_confidence = damage_probs[0][torch.argmax(damage_probs)].item()\n",
    "        \n",
    "        # –ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è\n",
    "        with torch.no_grad():\n",
    "            dirt_output = self.dirt_classifier(image_tensor)\n",
    "            dirt_probs = torch.softmax(dirt_output, dim=1)\n",
    "            dirt_status = 'dirty' if torch.argmax(dirt_probs) == 0 else 'clean'\n",
    "            dirt_confidence = dirt_probs[0][torch.argmax(dirt_probs)].item()\n",
    "        \n",
    "        return {\n",
    "            'damage': {'status': damage_status, 'confidence': damage_confidence},\n",
    "            'dirt': {'status': dirt_status, 'confidence': dirt_confidence}\n",
    "        }\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        if not os.path.exists(image_path):\n",
    "            return {\"error\": \"Image file not found\"}\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # –î–µ—Ç–µ–∫—Ü–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è\n",
    "        car_boxes = self.detect_car(image)\n",
    "        \n",
    "        if not car_boxes:\n",
    "            return {\"car_detected\": False, \"message\": \"No car detected\"}\n",
    "        \n",
    "        results = []\n",
    "        for i, box in enumerate(car_boxes):\n",
    "            # –í—ã—Ä–µ–∑–∞–µ–º –æ–±–ª–∞—Å—Ç—å –∞–≤—Ç–æ–º–æ–±–∏–ª—è\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            car_crop = original_image_rgb[y1:y2, x1:x2]\n",
    "            car_crop_pil = Image.fromarray(car_crop)\n",
    "            \n",
    "            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–∫—É—Ä—Å–∞\n",
    "            view = self.classify_view(car_crop_pil)\n",
    "            \n",
    "            # –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "            car_state = self.analyze_car_state(car_crop_pil)\n",
    "            \n",
    "            results.append({\n",
    "                'car_id': i,\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'view': view,\n",
    "                'state': car_state\n",
    "            })\n",
    "        \n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        self.visualize_results(original_image_rgb, results)\n",
    "        \n",
    "        return {\n",
    "            \"car_detected\": True,\n",
    "            \"cars_found\": len(results),\n",
    "            \"results\": results\n",
    "        }\n",
    "    \n",
    "    def visualize_results(self, image, results):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏\"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        img_with_boxes = image.copy()\n",
    "        \n",
    "        for result in results:\n",
    "            x1, y1, x2, y2 = result['bbox']\n",
    "            view = result['view']\n",
    "            damage = result['state']['damage']\n",
    "            dirt = result['state']['dirt']\n",
    "            \n",
    "            # –†–∏—Å—É–µ–º bounding box\n",
    "            color = (0, 255, 0) if damage['status'] == 'intact' else (255, 0, 0)\n",
    "            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 3)\n",
    "            \n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç\n",
    "            label = f\"{view}: {damage['status']}({damage['confidence']:.2f}), {dirt['status']}({dirt['confidence']:.2f})\"\n",
    "            cv2.putText(img_with_boxes, label, (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        plt.imshow(img_with_boxes)\n",
    "        plt.axis('off')\n",
    "        plt.title('Car Detection Results')\n",
    "        plt.show()\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É\n",
    "car_system = CarDetectionSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f407f14b-072f-428d-9f73-e767190c3fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4905f5cc01174deeab7bbe59a2a60032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>üöó Car Analysis System</h2>'), HTML(value=\"<p>Upload an image and click 'Process‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 8: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n",
    "def create_interactive_interface():\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è\"\"\"\n",
    "    \n",
    "    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    upload_btn = widgets.FileUpload(description='Upload Image', multiple=False)\n",
    "    process_btn = widgets.Button(description='Process Image', button_style='success')\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    def on_process_btn_clicked(b):\n",
    "        with result_output:\n",
    "            clear_output()\n",
    "            if upload_btn.value:\n",
    "                try:\n",
    "                    # –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–± –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "                    uploaded_file = upload_btn.value[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª\n",
    "                    \n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "                    with open('test_images/uploaded_image.jpg', 'wb') as f:\n",
    "                        f.write(uploaded_file['content'])\n",
    "                    \n",
    "                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "                    print(\"üîÑ Processing image...\")\n",
    "                    results = car_system.process_image('test_images/uploaded_image.jpg')\n",
    "                    \n",
    "                    if results.get('car_detected', False):\n",
    "                        print(\"‚úÖ Analysis completed!\")\n",
    "                        for car in results['results']:\n",
    "                            print(f\"\\nüöó Car {car['car_id'] + 1}:\")\n",
    "                            print(f\"   View: {car['view']}\")\n",
    "                            print(f\"   Damage: {car['state']['damage']['status']} \"\n",
    "                                  f\"(confidence: {car['state']['damage']['confidence']:.2f})\")\n",
    "                            print(f\"   Dirt: {car['state']['dirt']['status']} \"\n",
    "                                  f\"(confidence: {car['state']['dirt']['confidence']:.2f})\")\n",
    "                    else:\n",
    "                        print(\"‚ùå No cars detected\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error processing image: {e}\")\n",
    "                    print(\"Please try uploading a different image.\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Please upload an image first\")\n",
    "    \n",
    "    process_btn.on_click(on_process_btn_clicked)\n",
    "    \n",
    "    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h2>üöó Car Analysis System</h2>\"),\n",
    "        widgets.HTML(\"<p>Upload an image and click 'Process Image' to analyze</p>\"),\n",
    "        upload_btn,\n",
    "        process_btn,\n",
    "        result_output\n",
    "    ]))\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n",
    "create_interactive_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5de7210-f79d-40f4-a1ae-a0b40950bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ –í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a0413997fe46f5b58fe8e376b74108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>üöó Car Analysis System</h2>'), HTML(value=\"<p>Upload an image and click 'Process‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TraitError",
     "evalue": "The 'children' trait of a VBox instance contains an Instance of a TypedTuple which expected a Widget, not the NoneType None.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTraitError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# –î–æ–±–∞–≤–ª—è–µ–º –æ–±–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müì§ –í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m display(\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVBox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<h2>üöó Car Analysis System</h2>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<h3>–°–ø–æ—Å–æ–± 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞</h3>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_interactive_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<h3>–°–ø–æ—Å–æ–± 2: –£–∫–∞–∑–∞–Ω–∏–µ –ø—É—Ç–∏</h3>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_file_path_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/ipywidgets/widgets/widget_box.py:64\u001b[39m, in \u001b[36mBox.__init__\u001b[39m\u001b[34m(self, children, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, children=(), **kwargs):\n\u001b[32m     63\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mchildren\u001b[39m\u001b[33m'\u001b[39m] = children\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/ipywidgets/widgets/widget.py:503\u001b[39m, in \u001b[36mWidget.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Public constructor\"\"\"\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[38;5;28mself\u001b[39m._model_id = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmodel_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m Widget._call_widget_constructed(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    506\u001b[39m \u001b[38;5;28mself\u001b[39m.open()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:1355\u001b[39m, in \u001b[36mHasTraits.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items():\n\u001b[32m   1354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_trait(key):\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m         \u001b[38;5;28;43msetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1356\u001b[39m         changes[key] = Bunch(\n\u001b[32m   1357\u001b[39m             name=key,\n\u001b[32m   1358\u001b[39m             old=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1361\u001b[39m             \u001b[38;5;28mtype\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mchange\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1362\u001b[39m         )\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1364\u001b[39m         \u001b[38;5;66;03m# passthrough args that don't set traits to super\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:716\u001b[39m, in \u001b[36mTraitType.__set__\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_only:\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[33m'\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m trait is read-only.\u001b[39m\u001b[33m'\u001b[39m % \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:690\u001b[39m, in \u001b[36mTraitType.set\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: HasTraits, value: S) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     new_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:722\u001b[39m, in \u001b[36mTraitType._validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj._cross_validation_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    724\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._cross_validate(obj, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:3482\u001b[39m, in \u001b[36mContainer.validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   3479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m-> \u001b[39m\u001b[32m3482\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3484\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m t.cast(T, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:3494\u001b[39m, in \u001b[36mContainer.validate_elements\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   3492\u001b[39m     v = \u001b[38;5;28mself\u001b[39m._trait._validate(obj, v)\n\u001b[32m   3493\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TraitError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3496\u001b[39m     validated.append(v)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:810\u001b[39m, in \u001b[36mTraitType.error\u001b[39m\u001b[34m(self, obj, value, error, info)\u001b[39m\n\u001b[32m    801\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    802\u001b[39m             error.args = (\n\u001b[32m    803\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m trait contains \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m which \u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mexpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    804\u001b[39m                     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    808\u001b[39m                 ),\n\u001b[32m    809\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    812\u001b[39m \u001b[38;5;66;03m# this trait caused an error\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    814\u001b[39m     \u001b[38;5;66;03m# this is not the root trait\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:3492\u001b[39m, in \u001b[36mContainer.validate_elements\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   3490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[32m   3491\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3492\u001b[39m         v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_trait\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3493\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TraitError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m   3494\u001b[39m         \u001b[38;5;28mself\u001b[39m.error(obj, v, error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:722\u001b[39m, in \u001b[36mTraitType._validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj._cross_validation_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    724\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._cross_validate(obj, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:2311\u001b[39m, in \u001b[36mInstance.validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   2309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t.cast(T, value)\n\u001b[32m   2310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:815\u001b[39m, in \u001b[36mTraitType.error\u001b[39m\u001b[34m(self, obj, value, error, info)\u001b[39m\n\u001b[32m    812\u001b[39m \u001b[38;5;66;03m# this trait caused an error\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    814\u001b[39m     \u001b[38;5;66;03m# this is not the root trait\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(value, info \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info(), \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    817\u001b[39m \u001b[38;5;66;03m# this is the root trait\u001b[39;00m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mTraitError\u001b[39m: The 'children' trait of a VBox instance contains an Instance of a TypedTuple which expected a Widget, not the NoneType None."
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 8.1: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ –ø—É—Ç–∏\n",
    "def create_file_path_interface():\n",
    "    \"\"\"–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É\"\"\"\n",
    "    path_text = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä: test_images/my_car.jpg)',\n",
    "        description='Path to image:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    process_path_btn = widgets.Button(description='Process from Path', button_style='info')\n",
    "    path_output = widgets.Output()\n",
    "    \n",
    "    def on_process_path_click(b):\n",
    "        with path_output:\n",
    "            clear_output()\n",
    "            image_path = path_text.value.strip()\n",
    "            \n",
    "            if not image_path:\n",
    "                print(\"‚ö†Ô∏è Please enter a file path\")\n",
    "                return\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"‚ùå File not found: {image_path}\")\n",
    "                print(\"Available test images:\")\n",
    "                test_images = [f for f in os.listdir('test_images') if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                for img in test_images:\n",
    "                    print(f\"   test_images/{img}\")\n",
    "                return\n",
    "            \n",
    "            print(f\"üîÑ Processing: {image_path}\")\n",
    "            results = car_system.process_image(image_path)\n",
    "            \n",
    "            if results.get('car_detected', False):\n",
    "                print(\"‚úÖ Analysis completed!\")\n",
    "                for car in results['results']:\n",
    "                    print(f\"\\nüöó Car {car['car_id'] + 1}:\")\n",
    "                    print(f\"   View: {car['view']}\")\n",
    "                    print(f\"   Damage: {car['state']['damage']['status']} \"\n",
    "                          f\"(confidence: {car['state']['damage']['confidence']:.2f})\")\n",
    "                    print(f\"   Dirt: {car['state']['dirt']['status']} \"\n",
    "                          f\"(confidence: {car['state']['dirt']['confidence']:.2f})\")\n",
    "            else:\n",
    "                print(\"‚ùå No cars detected\")\n",
    "    \n",
    "    process_path_btn.on_click(on_process_path_click)\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìÅ –ò–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É:</h3>\"),\n",
    "        path_text,\n",
    "        process_path_btn,\n",
    "        path_output\n",
    "    ])\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –æ–±–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\n",
    "print(\"üì§ –í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\")\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h2>üöó Car Analysis System</h2>\"),\n",
    "    widgets.HTML(\"<h3>–°–ø–æ—Å–æ–± 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞</h3>\"),\n",
    "    create_interactive_interface(),\n",
    "    widgets.HTML(\"<h3>–°–ø–æ—Å–æ–± 2: –£–∫–∞–∑–∞–Ω–∏–µ –ø—É—Ç–∏</h3>\"),\n",
    "    create_file_path_interface()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f672359-69d3-445d-a926-2ef5e1c44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 8.2: –ü—Ä–æ—Å–º–æ—Ç—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "def show_test_images():\n",
    "    \"\"\"–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\"\"\"\n",
    "    test_dir = 'test_images'\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "        print(f\"üìÅ Created test_images folder\")\n",
    "        return\n",
    "    \n",
    "    images = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not images:\n",
    "        print(\"‚ùå No test images found in 'test_images/' folder\")\n",
    "        print(\"Please add some images or use the uploader\")\n",
    "        return\n",
    "    \n",
    "    print(\"üì∏ Available test images:\")\n",
    "    for i, img in enumerate(images):\n",
    "        print(f\"   {i+1}. {img}\")\n",
    "    \n",
    "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –ø–µ—Ä–≤—ã—Ö 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "    print(\"\\nüé® Preview (first 3 images):\")\n",
    "    fig, axes = plt.subplots(1, min(3, len(images)), figsize=(15, 5))\n",
    "    \n",
    "    if min(3, len(images)) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, img_name in enumerate(images[:3]):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(img_name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø–æ–∫–∞–∑–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "show_test_btn = widgets.Button(description=\"üëÄ –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\", button_style='info')\n",
    "test_images_output = widgets.Output()\n",
    "\n",
    "def on_show_test_click(b):\n",
    "    with test_images_output:\n",
    "        clear_output()\n",
    "        show_test_images()\n",
    "\n",
    "show_test_btn.on_click(on_show_test_click)\n",
    "\n",
    "print(\"\\nüì∏ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\")\n",
    "display(show_test_btn)\n",
    "display(test_images_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d7358-cee3-4288-8528-d962637d8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 9: –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "def test_with_sample_images():\n",
    "    \"\"\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö\"\"\"\n",
    "    test_images = [f for f in os.listdir('test_images') if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not test_images:\n",
    "        print(\"No test images found in 'test_images/' folder\")\n",
    "        return\n",
    "    \n",
    "    for img_name in test_images[:3]:  # —Ç–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        img_path = os.path.join('test_images', img_name)\n",
    "        print(f\"\\nüîç Testing: {img_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        results = car_system.process_image(img_path)\n",
    "        \n",
    "        if results.get('car_detected', False):\n",
    "            for car in results['results']:\n",
    "                print(f\"üöó Car: {car['view']} view\")\n",
    "                print(f\"   Damage: {car['state']['damage']['status']} \"\n",
    "                      f\"(confidence: {car['state']['damage']['confidence']:.2f})\")\n",
    "                print(f\"   Dirt: {car['state']['dirt']['status']} \"\n",
    "                      f\"(confidence: {car['state']['dirt']['confidence']:.2f})\")\n",
    "        else:\n",
    "            print(\"‚ùå No cars detected\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "test_with_sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfb1b7-7dd7-46b5-8c1e-c57db3b30cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 10: –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏\n",
    "def save_all_models():\n",
    "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º view classifier –µ—Å–ª–∏ –æ–Ω –æ–±—É—á–µ–Ω\n",
    "    if hasattr(car_system, 'view_classifier'):\n",
    "        torch.save(car_system.view_classifier.state_dict(), 'models/view_classifier.pth')\n",
    "        print(\"‚úÖ View classifier saved\")\n",
    "    \n",
    "    print(\"All models saved in 'models/' folder\")\n",
    "\n",
    "def load_all_models():\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "    if os.path.exists('models/view_classifier.pth'):\n",
    "        car_system.view_classifier.load_state_dict(\n",
    "            torch.load('models/view_classifier.pth', map_location=car_system.device)\n",
    "        )\n",
    "        print(\"‚úÖ View classifier loaded\")\n",
    "    \n",
    "    print(\"All available models loaded\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏\n",
    "save_all_models()\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π\n",
    "reload_btn = widgets.Button(description='Reload Models', button_style='info')\n",
    "reload_output = widgets.Output()\n",
    "\n",
    "def on_reload_clicked(b):\n",
    "    with reload_output:\n",
    "        clear_output()\n",
    "        load_all_models()\n",
    "        print(\"üîÑ Models reloaded!\")\n",
    "\n",
    "reload_btn.on_click(on_reload_clicked)\n",
    "display(reload_btn)\n",
    "display(reload_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d61a7-ada8-41f1-ba39-485063e00dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18a322-e31c-4a9d-8448-d22e175a6477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83301df1-92cf-43b6-b9b3-6a153f91e543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25acb8-c816-4474-a465-21af4f5ac6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f366c70-768e-4470-bc4b-4434b5e0d48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979fd88-66b9-4135-87de-71434eb795b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178228a2-b78e-4945-acaf-c588dfca6bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9015e6-608a-4a9c-ad01-ac35173ff3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
