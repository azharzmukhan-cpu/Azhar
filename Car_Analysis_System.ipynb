{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d37bbc9-d209-4e0e-833b-09ea0fd2d8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in ./myenv/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in ./myenv/lib/python3.13/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in ./myenv/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.13/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./myenv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./myenv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.13/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./myenv/lib/python3.13/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in ./myenv/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in ./myenv/lib/python3.13/site-packages (11.3.0)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.13/site-packages (3.10.6)\n",
      "Requirement already satisfied: scikit-learn in ./myenv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.13/site-packages (2.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./myenv/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./myenv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./myenv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: ipywidgets in ./myenv/lib/python3.13/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./myenv/lib/python3.13/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./myenv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myenv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 1: Установка зависимостей\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install opencv-python pillow matplotlib scikit-learn numpy\n",
    "!pip install ipywidgets  # для интерактивных элементов\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models, datasets\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aece385b-f77e-49e0-962f-c8ad21118c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: data/raw/car\n",
      "Created: data/raw/not_car\n",
      "Created: data/processed/views/train/front\n",
      "Created: data/processed/views/train/side\n",
      "Created: data/processed/views/train/rear\n",
      "Created: data/processed/views/val/front\n",
      "Created: data/processed/views/val/side\n",
      "Created: data/processed/views/val/rear\n",
      "Created: data/processed/damage/train/damaged\n",
      "Created: data/processed/damage/train/intact\n",
      "Created: data/processed/damage/val/damaged\n",
      "Created: data/processed/damage/val/intact\n",
      "Created: data/processed/dirt/train/dirty\n",
      "Created: data/processed/dirt/train/clean\n",
      "Created: data/processed/dirt/val/dirty\n",
      "Created: data/processed/dirt/val/clean\n",
      "Created: models\n",
      "Created: test_images\n",
      "Folder structure created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 2: Создание структуры папок\n",
    "def create_folder_structure():\n",
    "    folders = [\n",
    "        'data/raw/car',\n",
    "        'data/raw/not_car',\n",
    "        'data/processed/views/train/front',\n",
    "        'data/processed/views/train/side', \n",
    "        'data/processed/views/train/rear',\n",
    "        'data/processed/views/val/front',\n",
    "        'data/processed/views/val/side',\n",
    "        'data/processed/views/val/rear',\n",
    "        'data/processed/damage/train/damaged',\n",
    "        'data/processed/damage/train/intact',\n",
    "        'data/processed/damage/val/damaged', \n",
    "        'data/processed/damage/val/intact',\n",
    "        'data/processed/dirt/train/dirty',\n",
    "        'data/processed/dirt/train/clean',\n",
    "        'data/processed/dirt/val/dirty',\n",
    "        'data/processed/dirt/val/clean',\n",
    "        'models',\n",
    "        'test_images'\n",
    "    ]\n",
    "    \n",
    "    for folder in folders:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        print(f\"Created: {folder}\")\n",
    "    \n",
    "    # Создаем README файлы\n",
    "    for view in ['front', 'side', 'rear']:\n",
    "        with open(f'data/processed/views/train/{view}/README.txt', 'w') as f:\n",
    "            f.write(f\"Place {view} view car images here\")\n",
    "        with open(f'data/processed/views/val/{view}/README.txt', 'w') as f:\n",
    "            f.write(f\"Place {view} view car images here (validation)\")\n",
    "    \n",
    "    print(\"Folder structure created successfully!\")\n",
    "\n",
    "create_folder_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886cf92b-110d-45f9-ae17-dd7d1c74d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Поиск файлов в: /Users/ashko/Downloads\n",
      "--------------------------------------------------\n",
      "📁 Всего файлов в Загрузках: 56\n",
      "🖼️ Из них изображений: 21\n",
      "📋 Изображения в Загрузках:\n",
      "   📄 IMG_6538.PNG\n",
      "   📄 IMG_7344.JPG\n",
      "   📄 IMG_7024.PNG\n",
      "   📄 6f3f4105-ec19-4569-b106-941b5f325b56.JPG\n",
      "   📄 _.png\n",
      "   📄 car_scratch.png\n",
      "   📄 ChatGPT Image Aug 9, 2025 at 12_26_31 AM.png\n",
      "   📄 ChatGPT Image Sep 11, 2025 at 12_03_35 AM.png\n",
      "   📄 IMG_7497.JPG\n",
      "   📄 IMG_7496.JPG\n",
      "   ... и еще 11 изображений\n",
      "\n",
      "🔎 Поиск ваших файлов:\n",
      "   ✅ Car: найдено 1 файлов\n",
      "      📄 car_scratch.png\n",
      "   ❌ car_perfect_sides: не найдено\n",
      "   ❌ front: не найдено\n",
      "   ❌ rear: не найдено\n",
      "   ✅ car_scratch: найдено 1 файлов\n",
      "      📄 car_scratch.png\n",
      "   ❌ rust_and_scratch: не найдено\n",
      "   ❌ car_scratch_and_dent: не найдено\n",
      "\n",
      "📊 Всего найдено ваших файлов: 2\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 3: Исправленная функция copy_from_downloads\n",
    "def copy_from_downloads(target_folder, keywords=None, file_limit=10):\n",
    "    \"\"\"\n",
    "    Копирует изображения из папки Загрузки в целевую папку\n",
    "    \"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "    else:  # Linux/Mac\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    if not os.path.exists(downloads_path):\n",
    "        print(f\"❌ Папка Загрузки не найдена: {downloads_path}\")\n",
    "        return 0\n",
    "    \n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    \n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.JPG', '*.JPEG', '*.PNG']\n",
    "    all_images = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        all_images.extend(glob.glob(os.path.join(downloads_path, ext)))\n",
    "    \n",
    "    if keywords:\n",
    "        filtered_images = []\n",
    "        for img_path in all_images:\n",
    "            filename = os.path.basename(img_path).lower()\n",
    "            # Ищем ЛЮБОЕ из ключевых слов в названии файла\n",
    "            if any(keyword.lower() in filename for keyword in keywords):\n",
    "                filtered_images.append(img_path)\n",
    "        all_images = filtered_images\n",
    "    \n",
    "    images_to_copy = all_images[:file_limit]\n",
    "    \n",
    "    if not images_to_copy:\n",
    "        print(\"❌ Не найдено подходящих изображений в папке Загрузки\")\n",
    "        print(f\"Искал файлы содержащие: {keywords}\")\n",
    "        return 0\n",
    "    \n",
    "    copied_count = 0\n",
    "    for img_path in images_to_copy:\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            target_path = os.path.join(target_folder, filename)\n",
    "            \n",
    "            counter = 1\n",
    "            while os.path.exists(target_path):\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                target_path = os.path.join(target_folder, f\"{name}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "            \n",
    "            shutil.copy2(img_path, target_path)\n",
    "            print(f\"✅ Скопировано: {filename} -> {target_folder}\")\n",
    "            copied_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при копировании {filename}: {e}\")\n",
    "    \n",
    "    print(f\"📊 Скопировано файлов: {copied_count}/{len(images_to_copy)}\")\n",
    "    return copied_count\n",
    "\n",
    "# Добавьте эту функцию для отладки\n",
    "def debug_file_search():\n",
    "    \"\"\"Показывает какие файлы находит система\"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "    else:  # Linux/Mac\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    print(f\"🔍 Поиск файлов в: {downloads_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Все файлы в загрузках\n",
    "    all_files = os.listdir(downloads_path)\n",
    "    image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]\n",
    "    \n",
    "    print(f\"📁 Всего файлов в Загрузках: {len(all_files)}\")\n",
    "    print(f\"🖼️ Из них изображений: {len(image_files)}\")\n",
    "    \n",
    "    if image_files:\n",
    "        print(\"📋 Изображения в Загрузках:\")\n",
    "        for img in image_files[:10]:  # первые 10\n",
    "            print(f\"   📄 {img}\")\n",
    "        if len(image_files) > 10:\n",
    "            print(f\"   ... и еще {len(image_files) - 10} изображений\")\n",
    "    \n",
    "    # Ваши конкретные файлы\n",
    "    your_files = ['Car', 'car_perfect_sides', 'front', 'rear', 'car_scratch', 'rust_and_scratch', 'car_scratch_and_dent']\n",
    "    \n",
    "    print(\"\\n🔎 Поиск ваших файлов:\")\n",
    "    found_count = 0\n",
    "    for pattern in your_files:\n",
    "        found_files = [f for f in image_files if pattern.lower() in f.lower()]\n",
    "        if found_files:\n",
    "            print(f\"   ✅ {pattern}: найдено {len(found_files)} файлов\")\n",
    "            for file in found_files[:3]:  # первые 3\n",
    "                print(f\"      📄 {file}\")\n",
    "            if len(found_files) > 3:\n",
    "                print(f\"      ... и еще {len(found_files) - 3}\")\n",
    "            found_count += len(found_files)\n",
    "        else:\n",
    "            print(f\"   ❌ {pattern}: не найдено\")\n",
    "    \n",
    "    print(f\"\\n📊 Всего найдено ваших файлов: {found_count}\")\n",
    "\n",
    "# Запустите отладку чтобы увидеть что происходит\n",
    "debug_file_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cadcf40-4f3a-4942-85ed-6dcf0f902585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Ищу ваши папки в: /Users/ashko/Downloads\n",
      "------------------------------------------------------------\n",
      "✅ Найдена папка: Car\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_copied\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Запустите эту функцию\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mcopy_from_your_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Проверьте результат\u001b[39;00m\n\u001b[32m     91\u001b[39m check_data_availability()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mcopy_from_your_folders\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m images = []\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33m*.jpg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m*.jpeg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     images.extend(\u001b[43mglob\u001b[49m.glob(os.path.join(source_folder, ext)))\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   📷 Найдено изображений: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images:\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Создаем целевую папку\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# Ячейка 3.5: Копирование из ваших папок в нужные директории\n",
    "def copy_from_your_folders():\n",
    "    \"\"\"Копирует файлы из ваших папок в нужные директории обучения\"\"\"\n",
    "    if os.name == 'nt':  # Windows\n",
    "        downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "    else:  # Linux/Mac\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "    \n",
    "    print(f\"🔍 Ищу ваши папки в: {downloads_path}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Ваши папки и куда их копировать\n",
    "    folder_mapping = {\n",
    "        'Car': 'data/processed/views/train/front',\n",
    "        'car_perfect_sides': 'data/processed/views/train/side', \n",
    "        'front': 'data/processed/views/train/front',\n",
    "        'rear': 'data/processed/views/train/rear',\n",
    "        'car_scratch': 'data/processed/damage/train/damaged',\n",
    "        'rust_and_scratch': 'data/processed/damage/train/damaged',\n",
    "        'car_scratch_and_dent': 'data/processed/damage/train/damaged'\n",
    "    }\n",
    "    \n",
    "    total_copied = 0\n",
    "    found_folders = []\n",
    "    \n",
    "    # Ищем каждую папку\n",
    "    for folder_name, target_folder in folder_mapping.items():\n",
    "        source_folder = os.path.join(downloads_path, folder_name)\n",
    "        \n",
    "        if os.path.exists(source_folder) and os.path.isdir(source_folder):\n",
    "            found_folders.append(folder_name)\n",
    "            print(f\"✅ Найдена папка: {folder_name}\")\n",
    "            \n",
    "            # Ищем изображения в папке\n",
    "            images = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                images.extend(glob.glob(os.path.join(source_folder, ext)))\n",
    "            \n",
    "            print(f\"   📷 Найдено изображений: {len(images)}\")\n",
    "            \n",
    "            if images:\n",
    "                # Создаем целевую папку\n",
    "                os.makedirs(target_folder, exist_ok=True)\n",
    "                \n",
    "                # Копируем все изображения\n",
    "                folder_copied = 0\n",
    "                for img_path in images:\n",
    "                    try:\n",
    "                        filename = os.path.basename(img_path)\n",
    "                        target_path = os.path.join(target_folder, filename)\n",
    "                        \n",
    "                        # Чтобы избежать перезаписи\n",
    "                        counter = 1\n",
    "                        while os.path.exists(target_path):\n",
    "                            name, ext = os.path.splitext(filename)\n",
    "                            target_path = os.path.join(target_folder, f\"{name}_{counter}{ext}\")\n",
    "                            counter += 1\n",
    "                        \n",
    "                        shutil.copy2(img_path, target_path)\n",
    "                        print(f\"      ✅ {filename}\")\n",
    "                        folder_copied += 1\n",
    "                        total_copied += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"      ❌ Ошибка с {filename}: {e}\")\n",
    "                \n",
    "                print(f\"   📊 Скопировано из {folder_name}: {folder_copied} файлов\")\n",
    "            else:\n",
    "                print(f\"   ❌ В папке {folder_name} нет изображений\")\n",
    "        else:\n",
    "            print(f\"❌ Папка не найдена: {folder_name}\")\n",
    "    \n",
    "    print(f\"\\n📊 Итог:\")\n",
    "    print(f\"Найдено папок: {len(found_folders)}\")\n",
    "    print(f\"Скопировано файлов: {total_copied}\")\n",
    "    \n",
    "    if not found_folders:\n",
    "        print(\"\\n🔎 Содержимое папки Загрузки:\")\n",
    "        all_items = os.listdir(downloads_path)\n",
    "        folders = [item for item in all_items if os.path.isdir(os.path.join(downloads_path, item))]\n",
    "        print(f\"Всего папок в Загрузках: {len(folders)}\")\n",
    "        for folder in folders:\n",
    "            print(f\"   📁 {folder}\")\n",
    "    \n",
    "    return total_copied\n",
    "\n",
    "# Запустите эту функцию\n",
    "copy_from_your_folders()\n",
    "\n",
    "# Проверьте результат\n",
    "check_data_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f10499-1435-4ecf-8148-3fe0ac2654ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Проверка обучающих данных...\n",
      "📁 data/processed/views/train/front: 413 изображений\n",
      "📁 data/processed/views/train/side: 1037 изображений\n",
      "📁 data/processed/views/train/rear: 436 изображений\n",
      "✅ Данные для обучения готовы!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 3.5: Проверка и создание тестовых данных\n",
    "def check_and_create_test_data():\n",
    "    \"\"\"Проверяет наличие данных и создает тестовые если нужно\"\"\"\n",
    "    print(\"🔍 Проверка обучающих данных...\")\n",
    "    \n",
    "    # Папки которые должны существовать\n",
    "    required_folders = [\n",
    "        'data/processed/views/train/front',\n",
    "        'data/processed/views/train/side',\n",
    "        'data/processed/views/train/rear',\n",
    "        'data/processed/views/val/front',\n",
    "        'data/processed/views/val/side',\n",
    "        'data/processed/views/val/rear'\n",
    "    ]\n",
    "    \n",
    "    # Проверяем каждую папку\n",
    "    for folder in required_folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            print(f\"✅ Создана папка: {folder}\")\n",
    "    \n",
    "    # Проверяем есть ли изображения\n",
    "    train_folders = [\n",
    "        'data/processed/views/train/front',\n",
    "        'data/processed/views/train/side',\n",
    "        'data/processed/views/train/rear'\n",
    "    ]\n",
    "    \n",
    "    has_data = False\n",
    "    for folder in train_folders:\n",
    "        if os.path.exists(folder):\n",
    "            images = [f for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                print(f\"📁 {folder}: {len(images)} изображений\")\n",
    "                has_data = True\n",
    "            else:\n",
    "                print(f\"❌ {folder}: нет изображений\")\n",
    "    \n",
    "    if not has_data:\n",
    "        print(\"\\n📝 Создаю тестовые изображения...\")\n",
    "        create_sample_images()\n",
    "        print(\"✅ Тестовые изображения созданы!\")\n",
    "    \n",
    "    return has_data\n",
    "\n",
    "def create_sample_images():\n",
    "    \"\"\"Создает простые тестовые изображения\"\"\"\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Цвета для разных ракурсов\n",
    "    colors = {\n",
    "        'front': (255, 0, 0),    # Красный - перед\n",
    "        'side': (0, 255, 0),     # Зеленый - бок\n",
    "        'rear': (0, 0, 255)      # Синий - зад\n",
    "    }\n",
    "    \n",
    "    # Создаем по 5 изображений для каждого ракурса\n",
    "    for view, color in colors.items():\n",
    "        folder_path = f'data/processed/views/train/{view}'\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        for i in range(5):\n",
    "            # Создаем простое изображение с цветным прямоугольником\n",
    "            img_array = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "            img_array[20:80, 20:80] = color\n",
    "            \n",
    "            img = Image.fromarray(img_array)\n",
    "            img.save(os.path.join(folder_path, f'{view}_sample_{i+1}.jpg'))\n",
    "            print(f\"✅ Создано: {view}_sample_{i+1}.jpg\")\n",
    "    \n",
    "    # Создаем немного validation данных\n",
    "    for view in ['front', 'side', 'rear']:\n",
    "        val_folder = f'data/processed/views/val/{view}'\n",
    "        os.makedirs(val_folder, exist_ok=True)\n",
    "        \n",
    "        # Копируем по 1 изображению из train в val\n",
    "        train_folder = f'data/processed/views/train/{view}'\n",
    "        if os.path.exists(train_folder):\n",
    "            images = [f for f in os.listdir(train_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if images:\n",
    "                src_path = os.path.join(train_folder, images[0])\n",
    "                dst_path = os.path.join(val_folder, f'val_{images[0]}')\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                print(f\"✅ Создано validation: {dst_path}\")\n",
    "\n",
    "# Проверяем и создаем данные если нужно\n",
    "has_data = check_and_create_test_data()\n",
    "\n",
    "# Если данных нет, предлагаем варианты\n",
    "if not has_data:\n",
    "    print(\"\\n🎯 Доступные варианты:\")\n",
    "    print(\"1. Использовать созданные тестовые изображения\")\n",
    "    print(\"2. Скопировать ваши файлы из Загрузок\")\n",
    "    print(\"3. Загрузить свои изображения\")\n",
    "    \n",
    "    # Создаем кнопки для действий\n",
    "    use_test_btn = widgets.Button(description=\"✅ Использовать тестовые данные\", button_style='success')\n",
    "    copy_files_btn = widgets.Button(description=\"📥 Скопировать мои файлы\", button_style='info')\n",
    "    check_again_btn = widgets.Button(description=\"🔄 Проверить снова\", button_style='warning')\n",
    "    \n",
    "    test_data_output = widgets.Output()\n",
    "    \n",
    "    def on_use_test_click(b):\n",
    "        with test_data_output:\n",
    "            clear_output()\n",
    "            print(\"🔄 Запускаю обучение на тестовых данных...\")\n",
    "            # Здесь будет вызов функции обучения\n",
    "    \n",
    "    def on_copy_files_click(b):\n",
    "        with test_data_output:\n",
    "            clear_output()\n",
    "            print(\"📥 Используйте вкладку '🎯 Ваши файлы' для копирования\")\n",
    "            auto_sort_your_files()\n",
    "    \n",
    "    def on_check_again_click(b):\n",
    "        with test_data_output:\n",
    "            clear_output()\n",
    "            check_and_create_test_data()\n",
    "    \n",
    "    use_test_btn.on_click(on_use_test_click)\n",
    "    copy_files_btn.on_click(on_copy_files_click)\n",
    "    check_again_btn.on_click(on_check_again_click)\n",
    "    \n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h4>🚨 Нет данных для обучения!</h4>\"),\n",
    "        use_test_btn,\n",
    "        copy_files_btn, \n",
    "        check_again_btn,\n",
    "        test_data_output\n",
    "    ]))\n",
    "else:\n",
    "    print(\"✅ Данные для обучения готовы!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339c9454-de38-4e51-95dd-25ed47cec3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Для добавления ваших файлов:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c251af2df08041b48434d9a7faf15a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='🚀 Авто-сортировка моих файлов', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba9b198fa5a4e31832aa90af8af7015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ячейка для автоматической сортировки ваших файлов\n",
    "def auto_sort_your_files():\n",
    "    \"\"\"Автоматически сортирует ваши файлы по нужным папкам\"\"\"\n",
    "    found_files = analyze_your_files()\n",
    "    \n",
    "    if not found_files:\n",
    "        print(\"❌ Файлы не найдены. Проверьте что они в папке Загрузки\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n🚀 Автоматическая сортировка ваших файлов:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Правила сортировки для ваших файлов\n",
    "    sorting_rules = {\n",
    "        'front': 'data/processed/views/train/front',\n",
    "        'rear': 'data/processed/views/train/rear',\n",
    "        'car_perfect_sides': 'data/processed/views/train/side',\n",
    "        'car_scratch': 'data/processed/damage/train/damaged',\n",
    "        'rust_and_scratch': 'data/processed/damage/train/damaged', \n",
    "        'car_scratch_and_dent': 'data/processed/damage/train/damaged'\n",
    "    }\n",
    "    \n",
    "    total_copied = 0\n",
    "    \n",
    "    for filename, files in found_files.items():\n",
    "        if filename in sorting_rules:\n",
    "            target_folder = sorting_rules[filename]\n",
    "            print(f\"\\n📁 Сортировка '{filename}' -> {target_folder}:\")\n",
    "            \n",
    "            for file_path in files:\n",
    "                try:\n",
    "                    file_name = os.path.basename(file_path)\n",
    "                    target_path = os.path.join(target_folder, file_name)\n",
    "                    \n",
    "                    # Создаем папку если нет\n",
    "                    os.makedirs(target_folder, exist_ok=True)\n",
    "                    \n",
    "                    # Копируем файл\n",
    "                    shutil.copy2(file_path, target_path)\n",
    "                    print(f\"   ✅ {file_name}\")\n",
    "                    total_copied += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Ошибка с {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\n📊 Итого скопировано: {total_copied} файлов\")\n",
    "    \n",
    "    # Проверяем результат\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    check_data_availability()\n",
    "    \n",
    "    # Показываем что получилось\n",
    "    print(\"\\n🎯 Ваши файлы распределены:\")\n",
    "    for filename, target in sorting_rules.items():\n",
    "        if filename in found_files:\n",
    "            files_count = len(found_files[filename])\n",
    "            print(f\"   {filename} -> {target}: {files_count} файлов\")\n",
    "\n",
    "# Создаем кнопку для автоматической сортировки\n",
    "auto_sort_btn = widgets.Button(description=\"🚀 Авто-сортировка моих файлов\", button_style='success')\n",
    "auto_sort_output = widgets.Output()\n",
    "\n",
    "def on_auto_sort_click(b):\n",
    "    with auto_sort_output:\n",
    "        clear_output()\n",
    "        auto_sort_your_files()\n",
    "\n",
    "auto_sort_btn.on_click(on_auto_sort_click)\n",
    "\n",
    "print(\"🎯 Для добавления ваших файлов:\")\n",
    "display(auto_sort_btn)\n",
    "display(auto_sort_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e35a35-09ce-40e8-a0dd-c5ca332dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 4: Классы датасетов\n",
    "class ViewDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['front', 'side', 'rear']\n",
    "        self.images = []\n",
    "        \n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append({\n",
    "                            'path': os.path.join(class_dir, img_name),\n",
    "                            'label': class_idx\n",
    "                        })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        image = Image.open(img_info['path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_info['label']\n",
    "\n",
    "class DamageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['damaged', 'intact']\n",
    "        self.images = []\n",
    "        \n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append({\n",
    "                            'path': os.path.join(class_dir, img_name),\n",
    "                            'label': class_idx\n",
    "                        })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        image = Image.open(img_info['path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_info['label']\n",
    "\n",
    "# Трансформы\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e99f1d2-4ef9-4106-a875-67ae950cbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 5: Функции обучения\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, model_name):\n",
    "    \"\"\"Обучение модели с визуализацией прогресса\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    # Создаем график для live-обновления\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    plt.ion()  # Включаем интерактивный режим\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Обучение\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "        val_accuracy = 100 * val_correct / val_total if val_total > 0 else 0\n",
    "        \n",
    "        # Сохраняем метрики\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Сохраняем лучшую модель\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), f'models/{model_name}.pth')\n",
    "        \n",
    "        # Обновляем график\n",
    "        clear_output(wait=True)\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        \n",
    "        ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "        ax1.plot(val_losses, label='Val Loss', color='red')\n",
    "        ax1.set_title('Loss')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(train_accuracies, label='Train Accuracy', color='green')\n",
    "        ax2.plot(val_accuracies, label='Val Accuracy', color='orange')\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "        print(f'Best Val Accuracy: {best_accuracy:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    plt.ioff()\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0fd279d-dbde-4c96-9ab7-5371ba016169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "✅ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Обновленная функция обучения\n",
    "def train_view_classifier():\n",
    "    \"\"\"Обучение классификатора ракурсов с проверкой данных\"\"\"\n",
    "    print(\"🚗 Training View Classifier...\")\n",
    "    \n",
    "    # Проверяем наличие данных\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"❌ No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"❌ No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 Training images: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Модель\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 класса: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Обучение\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # Уменьшил до 5 эпох для теста\n",
    "    )\n",
    "    \n",
    "    print(\"✅ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# Запускаем обучение\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a184fdc9-d8e5-4351-96c8-82d015df3132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "✅ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Обновленная функция обучения\n",
    "def train_view_classifier():\n",
    "    \"\"\"Обучение классификатора ракурсов с проверкой данных\"\"\"\n",
    "    print(\"🚗 Training View Classifier...\")\n",
    "    \n",
    "    # Проверяем наличие данных\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"❌ No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"❌ No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 Training images: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Модель\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 класса: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Обучение\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # Уменьшил до 5 эпох для теста\n",
    "    )\n",
    "    \n",
    "    print(\"✅ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# Запускаем обучение\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12a19f0-4d66-45e9-8ecc-5f6bcd8a7c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "✅ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Обновленная функция обучения\n",
    "def train_view_classifier():\n",
    "    \"\"\"Обучение классификатора ракурсов с проверкой данных\"\"\"\n",
    "    print(\"🚗 Training View Classifier...\")\n",
    "    \n",
    "    # Проверяем наличие данных\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"❌ No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"❌ No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 Training images: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Модель\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 класса: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Обучение\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # Уменьшил до 5 эпох для теста\n",
    "    )\n",
    "    \n",
    "    print(\"✅ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# Запускаем обучение\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a4fa27-8030-4045-92c1-66ec66167295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "✅ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Обновленная функция обучения\n",
    "def train_view_classifier():\n",
    "    \"\"\"Обучение классификатора ракурсов с проверкой данных\"\"\"\n",
    "    print(\"🚗 Training View Classifier...\")\n",
    "    \n",
    "    # Проверяем наличие данных\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"❌ No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"❌ No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 Training images: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Модель\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 класса: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Обучение\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # Уменьшил до 5 эпох для теста\n",
    "    )\n",
    "    \n",
    "    print(\"✅ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# Запускаем обучение\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a223c0d6-e2ac-4c90-8de6-cacca35bbc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1172, Train Acc: 95.92%\n",
      "Val Loss: 0.0311, Val Acc: 100.00%\n",
      "Best Val Accuracy: 100.00%\n",
      "--------------------------------------------------\n",
      "✅ View classifier training completed!\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Обновленная функция обучения\n",
    "def train_view_classifier():\n",
    "    \"\"\"Обучение классификатора ракурсов с проверкой данных\"\"\"\n",
    "    print(\"🚗 Training View Classifier...\")\n",
    "    \n",
    "    # Проверяем наличие данных\n",
    "    if not check_and_create_test_data():\n",
    "        print(\"❌ No training data found! Please add images to data folders.\")\n",
    "        return None\n",
    "    \n",
    "    # Создаем датасеты\n",
    "    train_dataset = ViewDataset('data/processed/views/train', train_transform)\n",
    "    val_dataset = ViewDataset('data/processed/views/val', val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"❌ No training images found!\")\n",
    "        print(\"Please add images to:\")\n",
    "        print(\"- data/processed/views/train/front/\")\n",
    "        print(\"- data/processed/views/train/side/\") \n",
    "        print(\"- data/processed/views/train/rear/\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 Training images: {len(train_dataset)}\")\n",
    "    print(f\"📊 Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Модель\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)  # 3 класса: front, side, rear\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Обучение\n",
    "    model, train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=5, model_name='view_classifier'  # Уменьшил до 5 эпох для теста\n",
    "    )\n",
    "    \n",
    "    print(\"✅ View classifier training completed!\")\n",
    "    return model\n",
    "\n",
    "# Запускаем обучение\n",
    "view_model = train_view_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e95329-8f6d-467e-aafa-b6bc5312fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Для быстрого теста:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eae30d27a249358c36ce55d230401d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='⚡ Быстрый тест обучения', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b4f57fdb4482ba1cc06c2bff61d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ячейка 6.1: Функция для быстрого теста\n",
    "def quick_test_training():\n",
    "    \"\"\"Быстрый тест обучения на минимальных данных\"\"\"\n",
    "    print(\"⚡ Быстрый тест обучения...\")\n",
    "    \n",
    "    # Создаем тестовые данные если их нет\n",
    "    check_and_create_test_data()\n",
    "    \n",
    "    # Запускаем обучение\n",
    "    model = train_view_classifier()\n",
    "    \n",
    "    if model is not None:\n",
    "        print(\"🎉 Тест обучения завершен успешно!\")\n",
    "        print(\"Теперь вы можете:\")\n",
    "        print(\"1. Добавить больше своих изображений\")\n",
    "        print(\"2. Обучить на полном наборе данных\")\n",
    "        print(\"3. Протестировать систему\")\n",
    "    else:\n",
    "        print(\"❌ Тест не удался. Проверьте данные.\")\n",
    "\n",
    "# Кнопка для быстрого теста\n",
    "quick_test_btn = widgets.Button(description=\"⚡ Быстрый тест обучения\", button_style='info')\n",
    "quick_test_output = widgets.Output()\n",
    "\n",
    "def on_quick_test_click(b):\n",
    "    with quick_test_output:\n",
    "        clear_output()\n",
    "        quick_test_training()\n",
    "\n",
    "quick_test_btn.on_click(on_quick_test_click)\n",
    "\n",
    "print(\"\\n⚡ Для быстрого теста:\")\n",
    "display(quick_test_btn)\n",
    "display(quick_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e543c0-82e5-47e5-9ac2-908adf233671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashko/myenv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/ashko/myenv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ View classifier weights loaded\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 7: Car Detection System\n",
    "class CarDetectionSystem:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Инициализация моделей\n",
    "        self.car_detector = self._load_car_detector()\n",
    "        self.view_classifier = self._load_view_classifier()\n",
    "        self.damage_classifier = self._load_damage_classifier()\n",
    "        self.dirt_classifier = self._load_dirt_classifier()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def _load_car_detector(self):\n",
    "        model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        model.eval()\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _load_view_classifier(self):\n",
    "        model = models.resnet18(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "        # Попробуем загрузить обученные веса\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('models/view_classifier.pth', map_location=self.device))\n",
    "            print(\"✅ View classifier weights loaded\")\n",
    "        except:\n",
    "            print(\"⚠️  Using untrained view classifier\")\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _load_damage_classifier(self):\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _load_dirt_classifier(self):\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def detect_car(self, image):\n",
    "        image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.car_detector(image_tensor)\n",
    "        \n",
    "        car_boxes = []\n",
    "        if 'boxes' in predictions[0]:\n",
    "            for box, label, score in zip(predictions[0]['boxes'], \n",
    "                                       predictions[0]['labels'], \n",
    "                                       predictions[0]['scores']):\n",
    "                if label == 3 and score > 0.5:  # автомобиль в COCO\n",
    "                    car_boxes.append(box.cpu().numpy())\n",
    "        \n",
    "        return car_boxes\n",
    "    \n",
    "    def classify_view(self, car_image):\n",
    "        image_tensor = self.transform(car_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.view_classifier(image_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        view_classes = ['front', 'side', 'rear']\n",
    "        return view_classes[predicted.item()]\n",
    "    \n",
    "    def analyze_car_state(self, car_image):\n",
    "        image_tensor = self.transform(car_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Анализ повреждений\n",
    "        with torch.no_grad():\n",
    "            damage_output = self.damage_classifier(image_tensor)\n",
    "            damage_probs = torch.softmax(damage_output, dim=1)\n",
    "            damage_status = 'damaged' if torch.argmax(damage_probs) == 0 else 'intact'\n",
    "            damage_confidence = damage_probs[0][torch.argmax(damage_probs)].item()\n",
    "        \n",
    "        # Анализ загрязнения\n",
    "        with torch.no_grad():\n",
    "            dirt_output = self.dirt_classifier(image_tensor)\n",
    "            dirt_probs = torch.softmax(dirt_output, dim=1)\n",
    "            dirt_status = 'dirty' if torch.argmax(dirt_probs) == 0 else 'clean'\n",
    "            dirt_confidence = dirt_probs[0][torch.argmax(dirt_probs)].item()\n",
    "        \n",
    "        return {\n",
    "            'damage': {'status': damage_status, 'confidence': damage_confidence},\n",
    "            'dirt': {'status': dirt_status, 'confidence': dirt_confidence}\n",
    "        }\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        if not os.path.exists(image_path):\n",
    "            return {\"error\": \"Image file not found\"}\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Детекция автомобиля\n",
    "        car_boxes = self.detect_car(image)\n",
    "        \n",
    "        if not car_boxes:\n",
    "            return {\"car_detected\": False, \"message\": \"No car detected\"}\n",
    "        \n",
    "        results = []\n",
    "        for i, box in enumerate(car_boxes):\n",
    "            # Вырезаем область автомобиля\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            car_crop = original_image_rgb[y1:y2, x1:x2]\n",
    "            car_crop_pil = Image.fromarray(car_crop)\n",
    "            \n",
    "            # Классификация ракурса\n",
    "            view = self.classify_view(car_crop_pil)\n",
    "            \n",
    "            # Анализ состояния\n",
    "            car_state = self.analyze_car_state(car_crop_pil)\n",
    "            \n",
    "            results.append({\n",
    "                'car_id': i,\n",
    "                'bbox': [x1, y1, x2, y2],\n",
    "                'view': view,\n",
    "                'state': car_state\n",
    "            })\n",
    "        \n",
    "        # Визуализация результатов\n",
    "        self.visualize_results(original_image_rgb, results)\n",
    "        \n",
    "        return {\n",
    "            \"car_detected\": True,\n",
    "            \"cars_found\": len(results),\n",
    "            \"results\": results\n",
    "        }\n",
    "    \n",
    "    def visualize_results(self, image, results):\n",
    "        \"\"\"Визуализация результатов детекции\"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        img_with_boxes = image.copy()\n",
    "        \n",
    "        for result in results:\n",
    "            x1, y1, x2, y2 = result['bbox']\n",
    "            view = result['view']\n",
    "            damage = result['state']['damage']\n",
    "            dirt = result['state']['dirt']\n",
    "            \n",
    "            # Рисуем bounding box\n",
    "            color = (0, 255, 0) if damage['status'] == 'intact' else (255, 0, 0)\n",
    "            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 3)\n",
    "            \n",
    "            # Добавляем текст\n",
    "            label = f\"{view}: {damage['status']}({damage['confidence']:.2f}), {dirt['status']}({dirt['confidence']:.2f})\"\n",
    "            cv2.putText(img_with_boxes, label, (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        plt.imshow(img_with_boxes)\n",
    "        plt.axis('off')\n",
    "        plt.title('Car Detection Results')\n",
    "        plt.show()\n",
    "\n",
    "# Инициализируем систему\n",
    "car_system = CarDetectionSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f407f14b-072f-428d-9f73-e767190c3fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4905f5cc01174deeab7bbe59a2a60032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>🚗 Car Analysis System</h2>'), HTML(value=\"<p>Upload an image and click 'Process…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ячейка 8: Исправленный интерактивный интерфейс\n",
    "def create_interactive_interface():\n",
    "    \"\"\"Создает интерактивные кнопки для управления\"\"\"\n",
    "    \n",
    "    # Кнопка для загрузки изображения\n",
    "    upload_btn = widgets.FileUpload(description='Upload Image', multiple=False)\n",
    "    process_btn = widgets.Button(description='Process Image', button_style='success')\n",
    "    result_output = widgets.Output()\n",
    "    \n",
    "    def on_process_btn_clicked(b):\n",
    "        with result_output:\n",
    "            clear_output()\n",
    "            if upload_btn.value:\n",
    "                try:\n",
    "                    # Новый способ обработки загруженного файла\n",
    "                    uploaded_file = upload_btn.value[0]  # Берем первый файл\n",
    "                    \n",
    "                    # Сохраняем загруженное изображение\n",
    "                    with open('test_images/uploaded_image.jpg', 'wb') as f:\n",
    "                        f.write(uploaded_file['content'])\n",
    "                    \n",
    "                    # Обрабатываем изображение\n",
    "                    print(\"🔄 Processing image...\")\n",
    "                    results = car_system.process_image('test_images/uploaded_image.jpg')\n",
    "                    \n",
    "                    if results.get('car_detected', False):\n",
    "                        print(\"✅ Analysis completed!\")\n",
    "                        for car in results['results']:\n",
    "                            print(f\"\\n🚗 Car {car['car_id'] + 1}:\")\n",
    "                            print(f\"   View: {car['view']}\")\n",
    "                            print(f\"   Damage: {car['state']['damage']['status']} \"\n",
    "                                  f\"(confidence: {car['state']['damage']['confidence']:.2f})\")\n",
    "                            print(f\"   Dirt: {car['state']['dirt']['status']} \"\n",
    "                                  f\"(confidence: {car['state']['dirt']['confidence']:.2f})\")\n",
    "                    else:\n",
    "                        print(\"❌ No cars detected\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error processing image: {e}\")\n",
    "                    print(\"Please try uploading a different image.\")\n",
    "            else:\n",
    "                print(\"⚠️ Please upload an image first\")\n",
    "    \n",
    "    process_btn.on_click(on_process_btn_clicked)\n",
    "    \n",
    "    # Отображаем интерфейс\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h2>🚗 Car Analysis System</h2>\"),\n",
    "        widgets.HTML(\"<p>Upload an image and click 'Process Image' to analyze</p>\"),\n",
    "        upload_btn,\n",
    "        process_btn,\n",
    "        result_output\n",
    "    ]))\n",
    "\n",
    "# Запускаем интерфейс\n",
    "create_interactive_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5de7210-f79d-40f4-a1ae-a0b40950bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 Выберите способ загрузки изображения:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a0413997fe46f5b58fe8e376b74108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>🚗 Car Analysis System</h2>'), HTML(value=\"<p>Upload an image and click 'Process…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TraitError",
     "evalue": "The 'children' trait of a VBox instance contains an Instance of a TypedTuple which expected a Widget, not the NoneType None.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTraitError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Добавляем оба интерфейса\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📤 Выберите способ загрузки изображения:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m display(\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVBox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<h2>🚗 Car Analysis System</h2>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<h3>Способ 1: Загрузка файла</h3>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_interactive_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidgets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<h3>Способ 2: Указание пути</h3>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_file_path_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/ipywidgets/widgets/widget_box.py:64\u001b[39m, in \u001b[36mBox.__init__\u001b[39m\u001b[34m(self, children, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, children=(), **kwargs):\n\u001b[32m     63\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mchildren\u001b[39m\u001b[33m'\u001b[39m] = children\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/ipywidgets/widgets/widget.py:503\u001b[39m, in \u001b[36mWidget.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Public constructor\"\"\"\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[38;5;28mself\u001b[39m._model_id = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmodel_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m Widget._call_widget_constructed(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    506\u001b[39m \u001b[38;5;28mself\u001b[39m.open()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:1355\u001b[39m, in \u001b[36mHasTraits.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items():\n\u001b[32m   1354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_trait(key):\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m         \u001b[38;5;28;43msetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1356\u001b[39m         changes[key] = Bunch(\n\u001b[32m   1357\u001b[39m             name=key,\n\u001b[32m   1358\u001b[39m             old=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1361\u001b[39m             \u001b[38;5;28mtype\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mchange\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1362\u001b[39m         )\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1364\u001b[39m         \u001b[38;5;66;03m# passthrough args that don't set traits to super\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:716\u001b[39m, in \u001b[36mTraitType.__set__\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_only:\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[33m'\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m trait is read-only.\u001b[39m\u001b[33m'\u001b[39m % \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:690\u001b[39m, in \u001b[36mTraitType.set\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: HasTraits, value: S) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     new_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:722\u001b[39m, in \u001b[36mTraitType._validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj._cross_validation_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    724\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._cross_validate(obj, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:3482\u001b[39m, in \u001b[36mContainer.validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   3479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m-> \u001b[39m\u001b[32m3482\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3484\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m t.cast(T, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:3494\u001b[39m, in \u001b[36mContainer.validate_elements\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   3492\u001b[39m     v = \u001b[38;5;28mself\u001b[39m._trait._validate(obj, v)\n\u001b[32m   3493\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TraitError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3496\u001b[39m     validated.append(v)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:810\u001b[39m, in \u001b[36mTraitType.error\u001b[39m\u001b[34m(self, obj, value, error, info)\u001b[39m\n\u001b[32m    801\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    802\u001b[39m             error.args = (\n\u001b[32m    803\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m trait contains \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m which \u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mexpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    804\u001b[39m                     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    808\u001b[39m                 ),\n\u001b[32m    809\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    812\u001b[39m \u001b[38;5;66;03m# this trait caused an error\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    814\u001b[39m     \u001b[38;5;66;03m# this is not the root trait\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:3492\u001b[39m, in \u001b[36mContainer.validate_elements\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   3490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[32m   3491\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3492\u001b[39m         v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_trait\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3493\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TraitError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m   3494\u001b[39m         \u001b[38;5;28mself\u001b[39m.error(obj, v, error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:722\u001b[39m, in \u001b[36mTraitType._validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m    720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj._cross_validation_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    724\u001b[39m     value = \u001b[38;5;28mself\u001b[39m._cross_validate(obj, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:2311\u001b[39m, in \u001b[36mInstance.validate\u001b[39m\u001b[34m(self, obj, value)\u001b[39m\n\u001b[32m   2309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t.cast(T, value)\n\u001b[32m   2310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2311\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.13/site-packages/traitlets/traitlets.py:815\u001b[39m, in \u001b[36mTraitType.error\u001b[39m\u001b[34m(self, obj, value, error, info)\u001b[39m\n\u001b[32m    812\u001b[39m \u001b[38;5;66;03m# this trait caused an error\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    814\u001b[39m     \u001b[38;5;66;03m# this is not the root trait\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(value, info \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info(), \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    817\u001b[39m \u001b[38;5;66;03m# this is the root trait\u001b[39;00m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mTraitError\u001b[39m: The 'children' trait of a VBox instance contains an Instance of a TypedTuple which expected a Widget, not the NoneType None."
     ]
    }
   ],
   "source": [
    "# Ячейка 8.1: Альтернативный интерфейс для загрузки по пути\n",
    "def create_file_path_interface():\n",
    "    \"\"\"Интерфейс для указания пути к файлу\"\"\"\n",
    "    path_text = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Введите путь к изображению (например: test_images/my_car.jpg)',\n",
    "        description='Path to image:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='80%')\n",
    "    )\n",
    "    \n",
    "    process_path_btn = widgets.Button(description='Process from Path', button_style='info')\n",
    "    path_output = widgets.Output()\n",
    "    \n",
    "    def on_process_path_click(b):\n",
    "        with path_output:\n",
    "            clear_output()\n",
    "            image_path = path_text.value.strip()\n",
    "            \n",
    "            if not image_path:\n",
    "                print(\"⚠️ Please enter a file path\")\n",
    "                return\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"❌ File not found: {image_path}\")\n",
    "                print(\"Available test images:\")\n",
    "                test_images = [f for f in os.listdir('test_images') if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                for img in test_images:\n",
    "                    print(f\"   test_images/{img}\")\n",
    "                return\n",
    "            \n",
    "            print(f\"🔄 Processing: {image_path}\")\n",
    "            results = car_system.process_image(image_path)\n",
    "            \n",
    "            if results.get('car_detected', False):\n",
    "                print(\"✅ Analysis completed!\")\n",
    "                for car in results['results']:\n",
    "                    print(f\"\\n🚗 Car {car['car_id'] + 1}:\")\n",
    "                    print(f\"   View: {car['view']}\")\n",
    "                    print(f\"   Damage: {car['state']['damage']['status']} \"\n",
    "                          f\"(confidence: {car['state']['damage']['confidence']:.2f})\")\n",
    "                    print(f\"   Dirt: {car['state']['dirt']['status']} \"\n",
    "                          f\"(confidence: {car['state']['dirt']['confidence']:.2f})\")\n",
    "            else:\n",
    "                print(\"❌ No cars detected\")\n",
    "    \n",
    "    process_path_btn.on_click(on_process_path_click)\n",
    "    \n",
    "    return widgets.VBox([\n",
    "        widgets.HTML(\"<h3>📁 Или укажите путь к файлу:</h3>\"),\n",
    "        path_text,\n",
    "        process_path_btn,\n",
    "        path_output\n",
    "    ])\n",
    "\n",
    "# Добавляем оба интерфейса\n",
    "print(\"📤 Выберите способ загрузки изображения:\")\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h2>🚗 Car Analysis System</h2>\"),\n",
    "    widgets.HTML(\"<h3>Способ 1: Загрузка файла</h3>\"),\n",
    "    create_interactive_interface(),\n",
    "    widgets.HTML(\"<h3>Способ 2: Указание пути</h3>\"),\n",
    "    create_file_path_interface()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f672359-69d3-445d-a926-2ef5e1c44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 8.2: Просмотр тестовых изображений\n",
    "def show_test_images():\n",
    "    \"\"\"Показывает доступные тестовые изображения\"\"\"\n",
    "    test_dir = 'test_images'\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "        print(f\"📁 Created test_images folder\")\n",
    "        return\n",
    "    \n",
    "    images = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not images:\n",
    "        print(\"❌ No test images found in 'test_images/' folder\")\n",
    "        print(\"Please add some images or use the uploader\")\n",
    "        return\n",
    "    \n",
    "    print(\"📸 Available test images:\")\n",
    "    for i, img in enumerate(images):\n",
    "        print(f\"   {i+1}. {img}\")\n",
    "    \n",
    "    # Показываем превью первых 3 изображений\n",
    "    print(\"\\n🎨 Preview (first 3 images):\")\n",
    "    fig, axes = plt.subplots(1, min(3, len(images)), figsize=(15, 5))\n",
    "    \n",
    "    if min(3, len(images)) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, img_name in enumerate(images[:3]):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(img_name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Кнопка для показа тестовых изображений\n",
    "show_test_btn = widgets.Button(description=\"👀 Показать тестовые изображения\", button_style='info')\n",
    "test_images_output = widgets.Output()\n",
    "\n",
    "def on_show_test_click(b):\n",
    "    with test_images_output:\n",
    "        clear_output()\n",
    "        show_test_images()\n",
    "\n",
    "show_test_btn.on_click(on_show_test_click)\n",
    "\n",
    "print(\"\\n📸 Доступные изображения:\")\n",
    "display(show_test_btn)\n",
    "display(test_images_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d7358-cee3-4288-8528-d962637d8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 9: Тестовые функции\n",
    "def test_with_sample_images():\n",
    "    \"\"\"Тестирование системы на нескольких примерах\"\"\"\n",
    "    test_images = [f for f in os.listdir('test_images') if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not test_images:\n",
    "        print(\"No test images found in 'test_images/' folder\")\n",
    "        return\n",
    "    \n",
    "    for img_name in test_images[:3]:  # тестируем первые 3 изображения\n",
    "        img_path = os.path.join('test_images', img_name)\n",
    "        print(f\"\\n🔍 Testing: {img_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        results = car_system.process_image(img_path)\n",
    "        \n",
    "        if results.get('car_detected', False):\n",
    "            for car in results['results']:\n",
    "                print(f\"🚗 Car: {car['view']} view\")\n",
    "                print(f\"   Damage: {car['state']['damage']['status']} \"\n",
    "                      f\"(confidence: {car['state']['damage']['confidence']:.2f})\")\n",
    "                print(f\"   Dirt: {car['state']['dirt']['status']} \"\n",
    "                      f\"(confidence: {car['state']['dirt']['confidence']:.2f})\")\n",
    "        else:\n",
    "            print(\"❌ No cars detected\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Запускаем тестирование\n",
    "test_with_sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfb1b7-7dd7-46b5-8c1e-c57db3b30cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 10: Утилиты для работы с моделями\n",
    "def save_all_models():\n",
    "    \"\"\"Сохраняет все модели\"\"\"\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Сохраняем view classifier если он обучен\n",
    "    if hasattr(car_system, 'view_classifier'):\n",
    "        torch.save(car_system.view_classifier.state_dict(), 'models/view_classifier.pth')\n",
    "        print(\"✅ View classifier saved\")\n",
    "    \n",
    "    print(\"All models saved in 'models/' folder\")\n",
    "\n",
    "def load_all_models():\n",
    "    \"\"\"Загружает все сохраненные модели\"\"\"\n",
    "    if os.path.exists('models/view_classifier.pth'):\n",
    "        car_system.view_classifier.load_state_dict(\n",
    "            torch.load('models/view_classifier.pth', map_location=car_system.device)\n",
    "        )\n",
    "        print(\"✅ View classifier loaded\")\n",
    "    \n",
    "    print(\"All available models loaded\")\n",
    "\n",
    "# Сохраняем модели\n",
    "save_all_models()\n",
    "\n",
    "# Создаем кнопку для перезагрузки моделей\n",
    "reload_btn = widgets.Button(description='Reload Models', button_style='info')\n",
    "reload_output = widgets.Output()\n",
    "\n",
    "def on_reload_clicked(b):\n",
    "    with reload_output:\n",
    "        clear_output()\n",
    "        load_all_models()\n",
    "        print(\"🔄 Models reloaded!\")\n",
    "\n",
    "reload_btn.on_click(on_reload_clicked)\n",
    "display(reload_btn)\n",
    "display(reload_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d61a7-ada8-41f1-ba39-485063e00dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18a322-e31c-4a9d-8448-d22e175a6477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83301df1-92cf-43b6-b9b3-6a153f91e543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25acb8-c816-4474-a465-21af4f5ac6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f366c70-768e-4470-bc4b-4434b5e0d48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979fd88-66b9-4135-87de-71434eb795b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178228a2-b78e-4945-acaf-c588dfca6bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9015e6-608a-4a9c-ad01-ac35173ff3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
